# 5: EC2 Fundamentals 
- EC2: elastic compute cloud -> Infrastructure as a service. Main capabilities...
	- rending virtual machine (ec2)
	- storing data on virtual drives (EBS)
	- distributing load across machines (ELB)
	- scaling services using auto scaling group (ASG)
- config options: OS, CPU, RAM, storage, firewall rules (security group), network card (speed of card, pub. IP addr), bootstrap script
		- storage: network attacked (EBS & EFS) or hardware (EC2 instance store)
		- bootstrap script: EC2 User Data script (configure at first launch)
- AMI: Amazon Machine Image
	- a customization of an EC2 inst - your own software, config, OS, monitoring, etc. => faster boot time. Built for a specific region, can copy to others.
- Security Groups (SGs)
	- control how traffic is allowed in/ out of an instance. Only contain allow rules-- deny by default.
- Instance purchasing options: on demand, reserved, spot inst, dedicated host
	- reserved flavors: reserved instances, convertible reserved instances, scheduled reserved instances.


# 6: EC2
- IPs
	- public IPs must be unique across whole web. Private only unique w/in the network.
	- Elastic IP: a public IPv4 that you own as long as you don't delete it. Why? If you need consistent IP, since IP can change when you stop/start EC2 inst (but not good approach).
- EC2 Placement Groups. 3 types... 
	- cluster: low latency group in single AZ. High performance, high risk (if rack fails, all fails)
	- spread: instances spread across different hardware (max 7 inst/ psread group/ AZ). For critical applications.
	- partition: like spread, but across different partitions (which rely on different racks). Scales to 100s of instances/ AZ. Up to 7 partitions/ AZ.
- ENI: Elastic Network Interface
	- logical component in a VPC that represents a virtual network card. 
	- can create ENI independently and move them to dif EC2 inst for failover.
	- bound to specific AZ.
- EC2 Hibernate
	- Background: on first start of inst, OS boots and EC2 user data script is run. On following starts, the OS just boots up, then app starts, cache warms up-- all takes time. 
		- If not hibernating, other options are to stop (data on disk (EBS) kept intact for next start) or terminate the instance (all data lost).
	- Hibernate makes things much faster- OS not stopped/restarted. In memory (RAM) state is preserved (under the hood, it's written to file in root EBS vol. Vol must be encrypted.) Only avail for on-demand and reserved instances & particular instance families. Max hibernation is 60 days. 
- EC2 Nitro
	- underlying platform for next-gen EC2 inst: new virtualization tech -> better performance. Enhanced networking, HPC, IPv6, and higher speed EBS (Nitro is needed for 64k IOPs, max w/o Nitro is 32,000), better security
- vCPU (virtual CPU)
	- multithreading - mult. threads on one CPU. Each thread represents a vCPU
	- optimizing (config @ launch): instances come w/ combination of RAM and vCPU. May want to change the vCPU options:
		- # of CPU cores: e.g. decrease if you need ^ RAM but less CPUs, to reduce cost
		- # threads/ core: e.g. disabling multithreading is helpful for HPC workloads
- Capacity reservations: ensure you have EC2 capacity when needed. Single AZ, manual or planned end date (no commitment), immediate access


# 7: EC2 Instance Storage
- EBS Volumes
	- a network drive you can attach to an instance as it runs (some have multi-attach feature to connect to >1 inst) that persists data even after instance is terminated. Bound to AZ.
	- EBS snapshots (i.e. backup)
		- can copy across AZs & regions to replicate EBS vol there. Rec'd to detach before snapshotting but not required.
- EC2 Instance Store
	- high performance *hardware disk.* Does not preserve data like an EBS network drive does. E.g. good for cache.
- EBS Details
	- 6 types, options for both SDD & HDD characterized by size, throughput, & IOPS
		- general purpose
			- GP3: SSD, independently set IOPS and throughput
			- GP2: SSD, IOPS and throughput linked together
		- Provisioned IOPS (PIOPS) SSD (high IOPS)
			- IO1 & IO2. Both support EBS multi-attach
		- HDDs (low IOPS)
			- ST1: throughput optimized
			- SC1: cold HDD
	- encryption
		- when you encrypt an EBS vol, what's encrypted? 
			- data @ rest inside vol, in flight btw vol & inst, all snapshots, all volumes created from that snapshot
		- encryption/decryption handled by AWS and is very low latency, so is recommended. Leverages keys from KMS (AES-256)
	- RAID options
		- RAID 0: increased performance. Mediates EC2 inst and 2 EBS vols s.t. you have one 'logiacl' vol w/ perf benefits (space & iops) of the two underlying vols combined.
		- RAID 1: increased fault tolerance. like RAID 0 structurally but writes to BOTH EBS vols simultaneously instead of one or the other- hence ^ fault tolerance, none of the per benefits of RAID 0.
- EFS (Elastic File System)
	- managed NFS (network file system) that can be mounded onto many EC2. Works with ec2 inst across AZs. SG controls access to EFS, scales automatically, only Linux-based AMIs, expensive but pay for what you use. 
	- 2 performance modes: general purpose (default), max I/O (higher latency, throughput, highly parallel)
	- throughput modes: bursting (1TB = 50MiB/s + burst of up to 100 MiB/s), provisioned (set throughput regardless of storage size)
	- storage tiers: lifecycle management feature to move files after N days. 
		- standard (for frequently accessed files)
		- EFS-IA: infrequent access. Low storage cost + retrieval cost.
- EBS vs EFS:
	- EBS: attached to one ins at a time (usually), locked @ AZ level, provision in adv., pay for whats provisioned
	- EFS: multi AZ, attach to 100s of inst, only for Linux, billed for what you use. 